{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们谈起计算机视觉,首先想到的就是图像分类，这也是计算视觉中最基本的任务之一，在图像分类的基础上，还有更复杂和有意思的任务，如目标检测，物体定位，图像分割等，如图所示，其中目标检测是一件比较实际的且具有挑战性的计算机视觉任务，其可以看成图像分类与定位的结合，给定一张图片，目标检测系统要能够识别出图像的目标并给出其位置，由于图片中目标数是不定的，且要给出目标的精确位置，目标检测比分类任务更复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> ![dection](./pic/detection.jpg) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近年来，目标检测算法取得了很大的突破，比较流行的算法大致可以分为两类，一类是基于Region Proposal的R-CNN系列算法（R-CNN, Fast R-CNN, Faster R-CNN）,它们是two-stage方法，需要使用启发式方法（selective search）或者CNN网络（RPN）产生Region Proposal, 然后再在Regoin Proposal上做分类与回归。而另一类就是以YOLO,SSD为代表的one-stage算法，其仅仅使用一个CNN网络直接预测不同目标的类别与位置。本文介绍的是YOLO算法（You Only Look Once），它最大的特点就是简单且快速，可以满足实时检测的要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> ![bigpicture](./pic/bigpictrue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体来看，YOLO算法采用一个单独的CNN模型实现端到端的目标检测，整个系统如图所示： \n",
    "<center> ![yolo](./pic/yolo.png) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先将输入图片resize到448x448,然后送入CNN网络，最后处理网络预测结果得到检测的目标，相比R-CNN算法，其是一个统一的框架，速度更快，而且YOLO算法的训练过程也是端到端的。\n",
    "1. 缩放输入图片\n",
    "2. 将图片送入到卷积神经网络进行预测\n",
    "3. 通过预测的结果进行置信度的阈值处理，得到最终结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络结构\n",
    "YOLO算法采用卷积网络来提取特征，然后使用全连接层得到预测值，网络结构参考GooLenet\n",
    "模型，包含24个卷积层和2个全连接层，如图所示：\n",
    "<center> ![network](./pic/network.png)  </center>\n",
    "\n",
    "除了上面的结构，论文中还提出一个轻量级版本的Fast YOLO，其仅使用9个卷积层，并且卷积层中使用更少的卷积核。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法思想\n",
    "YOLO会把输入图片分割成SxS个网格，如果某一个目标的中心点落在某个网格中，那么对应的那个网格就负责预测该目标的大小和类别。\n",
    "<center> ![dog](./pic/dog.png) </center>\n",
    "\n",
    "如上图所示，狗的中心点落在蓝色的网格中，所以蓝色的网格就负责这个目标的信息预测。\n",
    "每个网络都会预测B个bounding box和该bounding box对应的置信度Confidence以及bounding box预测目标的位置，其中置信度Confidence用来反映这个网络是否包含目标以及bounding box的准确性，其定义如下：\n",
    "$$ conf = Pr(obj)*IOU_{pred}^{truth} $$\n",
    "\n",
    "如果一个网格不包含目标，那么$Pr(obj)$就等于0，否则等于1，所以$conf$代表预测出来的bounding box同groundtruth的IOU。\n",
    "\n",
    "此外每个bounding box由5个预测量组成：(x,y,w,h,confidence)，x,y是bounding box中心点相对于网络坐标的偏移量比例，取值是0-1之间，也就是它们对网格的尺寸作归一化处理。同样，w,h相对于图片尺寸进行归一化，因此取值范围也是[0,1]\n",
    "每个网络除了预测bounding box之外，还会预测C个条件概率  $Pr(Class_{i}|Object)$,这个条件概率表示为当网格中存在目标的时候，目标类别的概率分布,条件概率针对的是每一个网络，不是每一个bounding box\n",
    "<center> ![tensor](./pic/tensor.png) </center>\n",
    "在测试阶段，YOLO会将条件概率和每个bounding box的confidence相乘\n",
    "$$ Pr(Class_{i}|Object)*Pr(Object)*IOU_{pred}^{truth} = Pr(Class_{i})*IOU_{pred}^{truth}$$\n",
    "上述公式是针对每一个bounding box而言的目标类别概率分布的置信度,这个置信度同时包含了两方面的信息，一个是目标属于某个类别的概率，一个是预测的bounding box离ground truth的距离\n",
    "<center> ![yolov1](./pic/yolov1.png) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss设计\n",
    "YOLO算法将目标检测看成回归问题，所以采用sum-squared error损失函数，如下式所示：\n",
    "<center> ![loss](./pic/loss.png) </center>\n",
    "\n",
    "上式中包含三个部分，坐标预测误差，confidence预测误差，类别预测误差，$1_{ij}^{obj}$表示第i个网格中的第j个bounding box是否负责当前的object\n",
    "实际情况下，YOLO在每张图片会预测7x7x2=98个bounding box, 但是只有很少的bounding box包含目标，那些不包含目标的bounding box的confidence在训练的过程中很快变为0,所有那些包含目标的网格预测的bounding box产生的梯度会急剧变化，导致训练不稳定，最终可能会出现loss不收敛，为了改善这种情况，论文作者调整了bounding box的坐标误差和没有包含目标的confidence的误差权重，即是公式中的 $\\lambda_{coord}$, $\\lambda_{noobj}$,分别是5和0.5.这样做的目的是不允许坐标变化过大，所以添加一个系数放大它们的误差，达到惩罚的目的。此外，由于bounding box的大小对位置误差敏感性不同，所以使用开方操作减少这种影响。\n",
    "需要注意的是，YOLO算法中每个网格预测两个bounding box, 最终只有一个bounding box来负责当前目标的位置的预测，它们通过confidence比较，也就是IOU比较，胜出的是分数较高的那个bounding box,进行loss计算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络预测\n",
    "YOLO算法的预测使用非极大值抑制(Non-maximum suppression, NMS), NMS算法首先从所有的检测框中找到置信度最大的那个框，然后逐个计算其与剩余框的IOU, 如果其值大于一定的阈值，那么就剔除; 对剩余的检测框重复上述过程，直到处理完所有的检测框。\n",
    "YOLO处理过程为： 对于98个bounding boxes, 首先将将小于置信度阈值的值置0，然后分类别地根据置信度排序进行NMS, 这里的NMS处理结果不是剔除，而是将其置信度值置0，最后才确定各个bounding box的类别，当其置信度值不为0才做出检测结果输出。\n",
    "<center> ![nms](./pic/NMS.png) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法优缺点\n",
    "* 优点\n",
    "  - 快。YOLO采用一个CNN网络来实现检测，训练与预测都是端到端的，简洁而且速度快\n",
    "  - 背景误检率低。YOLO在训练和推理过程中能看到整张图像的信息，不容易对背景误判\n",
    "  - 通用性强。YOLO对于艺术类作品中物体检测同样适用\n",
    "* 缺点\n",
    "\n",
    "  YOLO中各个网格仅仅预测两个边界框，而且属于一个类别，对于小物体，YOLO的表现差强人意，此外，YOLO存在定位不准确的问题，特别是对于不寻常比例的目标\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
